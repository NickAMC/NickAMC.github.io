---
title: 'Basic Report'
author: "Nick Climaco"
date: "`r Sys.Date()`"
output:
    html_document:
        highlight: pygments
        theme: cerulean
        toc: true
        toc_float: true
        code_folding: hide
editor_options:
    chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE,
                      tidy.opts = list(width.cutoff = 80), tidy = TRUE)
```

# Overview

> In this homework assignment, you will explore, analyze and model a data set containing information on crime for various neighborhoods of a major city. Each record has a response variable indicating whether or not the crime rate is above the median crime rate (1) or not (0).

> Your objective is to build a binary logistic regression model on the training data set to predict whether the neighborhood will be at risk for high crime levels. You will provide classifications and probabilities for the evaluation data set using your binary logistic regression model. You can only use the variables given to you (or variables that you derive from the variables provided). Below is a short description of the variables of interest in the data set

```{r, include = FALSE}
library(tidyverse)
library(data.table)
library(kableExtra)
library(knitr)
library(broom)
library(ggplot2)
library(corrplot)
library(car)
library(GGally)
library(caret)
library(pROC)
library(e1071)
library(tm)
```

# Data Exploration

```{r, include=FALSE}
# using fread from data.table library for faster read time
train_df <- fread('https://raw.githubusercontent.com/Nick-Climaco/Rdataset/main/crime-training-data_modified.csv')
eval_df <- fread('https://raw.githubusercontent.com/Nick-Climaco/Rdataset/main/crime-evaluation-data_modified.csv')
```

In this section, we will be exploring the data and familiarizing ourselves with 'features' we can use for the model building process. This training data has 466 observations, 1 target variable, and 12 predictor variables. First, we can take a look at the distribution of each predictor variable so we can assess the necessary steps to take in order generate the best fit for the model later on. 

#### Distribution of Each Predictor Variable 


```{r}
par(mfrow = c(4,4), mar = c(3,3,1,1))

for (col_name in names(train_df)) {
    hist(train_df[[col_name]], main = paste(col_name), xlab = "Value")
}

par(mfrow = c(1,1))
```


```{r}
kable(tidy(train_df), "pipe")
```

```{r}
show_summary <- function(df) {
  cat(rep("+", 50), "\n")
  cat(paste("DIMENSIONS : (", nrow(df), ", ", ncol(df), ")\n", sep = ""), "\n")
  cat(rep("+", 50), "\n")
  cat("COLUMNS:\n", "\n")
  cat(names(df), "\n")
  cat(rep("+", 50), "\n")
  cat("DATA INFO:\n", "\n")
  cat(sapply(df, class), "\n")
  cat(rep("+", 50), "\n")
  cat("MISSING VALUES:\n", "\n")
  cat(colSums(is.na(df)), "\n")
}

show_summary(train_df)
```

It seems the data is already fairly clean. There are no missing values in this dataset. All the explanatory variables have the right datatype. The next step is to look for multicollinearity. 

```{r}
# correlation plot
correlation_Matrix <- cor(train_df[,1:12])

corrplot(correlation_Matrix, method = 'color', type = 'upper', addCoef.col = "black", number.cex = 0.7)
```

I want to remove any high correlation anything above 0.7 will be remove to create an absence of multicollinearity. So, the variable **dis** has high negative correlation with **indus**, **nox**, and ***age***. Based on this correlation plot, we will remove the following variables in order to minimize multicollinearity: **dis**, **tax**, and **medv**.

```{r}
train_df <- train_df |> 
    mutate(crime = ifelse(target == 1, 'high', 'low'))

df_2 <- train_df |> 
    select(indus, nox, age, dis, crime)
ggpairs(data = df_2, columns = 1:4, ggplot2::aes(color = crime))
```

```{r}
train_df <- train_df |> 
    select(-dis, -tax, -medv, -nox)
```

***

# Data Preparation

After removing the high correlated variables, we can observe that the updated correlation plot has minimal collinearity between the indepedent predictor variable which is what we want to achieve.

```{r}
correlation_Matrix <- cor(train_df[,1:8])

corrplot(correlation_Matrix, method = 'color', type = 'upper', addCoef.col = "black", number.cex = 0.7)
```

```{r}
train_df <- train_df |> 
    select(-crime)
```

***

# Model Building

We start off with a simple logistic model and then we can work our way up to build the best fitting model. 

## Simple/Base Logistic Model

With this model, we will set a base AIC value of 522.46 with only one predictor variable in this case **zn** variable/feature. We expect the first model to having the worst AIC value. 

```{r}
simple_model <- glm(target ~ zn, data = train_df, family = "binomial")
summary(simple_model)
```

## Everything Model

For the second model, we will include all the predictor variables that are linearly independent. We will get a better AIC value of 292 which might not be the best. 

```{r}
everything_model <- glm(target ~ . , data = train_df, family = "binomial")
summary(everything_model)
```

After creating the everything_model, we wanted to double check with vif() function to check the collinearity of the variable. The table below shows that there is relatively low correlation between the predictor variables. 

```{r}
data.frame(vif(everything_model))
```

## Backward Selection



```{r}
step(everything_model, direction = "backward", scope = formula(everything_model))
```

## Forward Selection

```{r}
step(simple_model, direction = "forward", scope = formula(everything_model))
```

With both forward and backward selection, both logit model performs similar with having AIC value of 291.7. Also, both direction gave the formula for target ~ zn + rad + age+ ptratio + indus + rm. 

***

# Model Selection

The step model has the lower AIC value meaning that its has the lowest prediction error relative to the other models. The first model, we expected, to have the worst AIC since it was not able to predict a majority of the data. Next, the second model where it had all the variables had a significantly better AIC value which is still not the best model we could have had because the third model using the a step selection process where both direction forward selection and backward elimination yielded the same result which was surprising. In this case, the step model was the model we could have made with predictor variables in this dataset. So, we will be picking the step model to predict the target variable in the eval_df. 

```{r}
step_mod <- glm(target ~ zn + rad + age + ptratio + indus + rm, family = binomial, data = train_df)

predictions <- predict(step_mod, eval_df, type = "response")

threshold <- 0.5

binary_predictions <- ifelse(predictions >= threshold, 1, 0)

eval_df$target_pred <- binary_predictions
```

```{r}
model_names <- c("simple", "everything", "step")
aic_values <- c(simple_model$aic, everything_model$aic, step_mod$aic)

kable(cbind(model_names, aic_values), col.names = c("Model Name", "AIC Value")) |> 
    kable_styling(full_width = T)
```


# Predictions 

```{r}
kable(eval_df) |> 
    kable_styling(full_width = T)
```

# Resources

Medium Post: [Top 5 Assumption for Logistic Regression](https://dhirajkumarblog.medium.com/top-5-assumptions-for-logistic-regression-96b11d24d357)

https://www.rdocumentation.org/packages/caret/versions/3.45/topics/confusionMatrix
